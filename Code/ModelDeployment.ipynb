{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea38e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for required files\n",
    "!mkdir -p opt/ml/model  \n",
    "!cp model.joblib opt/ml/model/model.joblib\n",
    "!cp imports_featurizer.pkl opt/ml/model/imports_featurizer.pkl\n",
    "!cp section_names_featurizer.pkl opt/ml/model/section_names_featurizer.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19afad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    # Process the input data if necessary\n",
    "    processed_data = process_input(input_data)\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(processed_data)\n",
    "    #print(predictions)\n",
    "    return predictions\n",
    "\n",
    "def process_input(input_data):\n",
    "    # Process input data as needed before passing to the model for prediction\n",
    "    NgramFeaturesList_pred = np.array(input_data['NgramFeaturesList_pred'])\n",
    "    importsCorpus_pred = input_data['importsCorpus_pred']\n",
    "    sectionNames_pred = input_data['sectionNames_pred']\n",
    "    numSections_pred = int(input_data['numSections_pred'])\n",
    "    \n",
    "\n",
    "    # Load featurizers\n",
    "    imports_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"imports_featurizer.pkl\"))\n",
    "    section_names_featurizer = joblib.load(os.path.join(\"opt/ml/model\", \"section_names_featurizer.pkl\"))\n",
    "    #print(NgramFeaturesList_pred, importsCorpus_pred, sectionNames_pred, numSections_pred)\n",
    "    #print(imports_featurizer, section_names_featurizer)\n",
    "    # Transform text features\n",
    "    importsCorpus_pred_transformed = imports_featurizer.transform([importsCorpus_pred])\n",
    "    sectionNames_pred_transformed = section_names_featurizer.transform([sectionNames_pred])\n",
    "\n",
    "    # Concatenate features into a single sparse matrix\n",
    "    processed_data = hstack([csr_matrix(NgramFeaturesList_pred),\n",
    "                             importsCorpus_pred_transformed,\n",
    "                             sectionNames_pred_transformed,\n",
    "                             csr_matrix([numSections_pred]).transpose()])\n",
    "    #print(processed_data)\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    res = int(prediction[0])\n",
    "    respJSON = {'Output': res}\n",
    "    return respJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0658afb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "joblib\n",
    "scipy\n",
    "numpy\n",
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ca9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib\n",
      "inference.py\n",
      "imports_featurizer.pkl\n",
      "section_names_featurizer.pkl\n",
      "requirements.txt\n",
      "opt/\n",
      "opt/ml/\n",
      "opt/ml/model/\n",
      "opt/ml/model/model.joblib\n",
      "opt/ml/model/section_names_featurizer.pkl\n",
      "opt/ml/model/imports_featurizer.pkl\n",
      "opt/ml/model/.ipynb_checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# Tarballing the required files\n",
    "!tar -cvpzf modeldeployment.tar.gz model.joblib inference.py imports_featurizer.pkl section_names_featurizer.pkl requirements.txt opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663bb5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:804624801206:model/sklearn-test2024-04-04-22-54-36\n",
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:804624801206:endpoint-config/sklearn-epc2024-04-04-22-54-37\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:804624801206:endpoint/sklearn-local-ep2024-04-04-22-54-37\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "{'EndpointName': 'sklearn-local-ep2024-04-04-22-54-37', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:804624801206:endpoint/sklearn-local-ep2024-04-04-22-54-37', 'EndpointConfigName': 'sklearn-epc2024-04-04-22-54-37', 'ProductionVariants': [{'VariantName': 'sklearnvariant', 'DeployedImages': [{'SpecifiedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ResolvedImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn@sha256:93e5fa7425580265fc8e0b1c06f51ff7a2690adf844cd9b8281634b251c593c1', 'ResolutionTime': datetime.datetime(2024, 4, 4, 22, 54, 38, 398000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2024, 4, 4, 22, 54, 37, 673000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 4, 4, 23, 1, 35, 260000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '4238baf2-767a-40af-9936-0c14626c65f4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '4238baf2-767a-40af-9936-0c14626c65f4', 'content-type': 'application/x-amz-json-1.1', 'content-length': '766', 'date': 'Thu, 04 Apr 2024 23:01:38 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess\n",
    "\n",
    "# Setting up Boto3\n",
    "client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "boto_session = boto3.session.Session()\n",
    "s3 = boto_session.resource('s3')\n",
    "region = boto_session.region_name\n",
    "print(region)\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = \"arn:aws:iam::804624801206:role/LabRole\"\n",
    "\n",
    "# Retrieving SKLearn image URI\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")\n",
    "\n",
    "# Specifying the S3 bucket\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Uploading the model tarball to S3\n",
    "model_artifacts = f\"s3://{default_bucket}/modeldeployment.tar.gz\"\n",
    "response = s3.meta.client.upload_file('modeldeployment.tar.gz', default_bucket, 'modeldeployment.tar.gz')\n",
    "\n",
    "# Creating the model\n",
    "model_name = \"sklearn-test\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_model_response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            \"Image\": image_uri,\n",
    "            \"Mode\": \"SingleModel\",\n",
    "            \"ModelDataUrl\": model_artifacts,\n",
    "            \"Environment\": {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn=role,\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])\n",
    "\n",
    "# Creating the endpoint configuration\n",
    "sklearn_epc_name = \"sklearn-epc\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"sklearnvariant\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.t2.medium\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Endpoint Configuration Arn: \" + endpoint_config_response[\"EndpointConfigArn\"])\n",
    "\n",
    "# Creating the endpoint\n",
    "endpoint_name = \"sklearn-local-ep\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=sklearn_epc_name,\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "# Monitoring the creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(5)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4297ac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Output': 1}\n"
     ]
    }
   ],
   "source": [
    "# Testing the endpoint\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Initialize the SageMaker runtime client\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Define your input data\n",
    "input_data = {\n",
    "    'NgramFeaturesList_pred': [[24183, 3382, 304, 17, 923, 636, 358, 275, 128, 635, 358, 613, 389, 384, 448, 12, 380, 170, 307, 122, 224, 203, 51, 338, 521, 111, 395, 215, 175, 419, 264, 397, 287, 106, 487, 236, 16, 277, 459, 594, 469, 241, 155, 163, 158, 230, 215, 443, 80, 46, 44, 216, 68, 42, 36, 48, 161, 29, 240, 145, 139, 52, 20, 75, 99, 33, 224, 161, 38, 226, 729, 139, 27, 168, 19, 68, 269, 271, 236, 33, 197, 207, 337, 1114, 126, 111, 255, 175, 47, 46, 60, 318, 129, 79, 16, 223, 162, 79, 15, 157]],\n",
    "    'importsCorpus_pred': \"kernel32 shlwapi ole32 shell32 user32\",\n",
    "    'sectionNames_pred': \".text .rdata .data .rsrc .reloc\",\n",
    "    'numSections_pred': \"5\"\n",
    "}\n",
    "\n",
    "# Convert input data to JSON string\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sklearn-local-ep2024-04-04-22-54-37'\n",
    "\n",
    "# Call the endpoint\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType='application/json',\n",
    "                                   Body=payload)\n",
    "\n",
    "# Decode and print the response\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
